{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes neuronales junto con NeuralODEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a mezclar los ejemplos vistos anteriormente, para ello vamos a crear una red neuronal la cual también pase por una NeuralODE, en este caso prefiero poner una aumentada y así evitar el problema anterior. La teoria de estas ya las vimos antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using DifferentialEquations\n",
    "using DiffEqFlux\n",
    "using Plots\n",
    "using Flux: train!\n",
    "using Distributions\n",
    "using DiffEqFlux, DifferentialEquations\n",
    "using Statistics, LinearAlgebra, Plots\n",
    "using Flux.Data: DataLoader, Flux\n",
    "using Optimization, OptimizationOptimJL\n",
    "using OptimizationFlux, Random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos como simpre generando los dastos que vamos a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function Noise_Sine(x)\n",
    "    return sin(2π*x) + rand(Normal(0,0.05))\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_train = Float32.(hcat(0:0.01:2...))\n",
    "y_train = Float32.(Noise_Sine.(t_train))\n",
    "y_test = Float32.(Noise_Sine.(t_train))\n",
    "trange = t_train[1,:]\n",
    "tspan = (t_train[1], t_train[end])\n",
    "t_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(t_train[1,:], y_train[1,:], label=\"training data\", title=\"Sine function with noise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dudt = Chain(Dense(21 => 30, celu),\n",
    "            Dense(30 => 30, relu),\n",
    "            Dense(30 => 25, relu),\n",
    "            Dense(25 => 21, tanh_fast)) # Creamos el modelo que va a ser nuestra función diferenciada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A esta NN la vamos a hacer pasar por una NerualODE y extraemos los paráemtros de este modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffeqarray_to_array(x) = reshape(x, size(x)[1:2]) # Esto acomoda la solución de la EDO en un arreglo de 2 dimensiones 21 x length(trange)\n",
    "\n",
    "n_ode = NeuralODE(dudt, tspan, Tsit5(), save_everystep = false,\n",
    "reltol = 1e-3, abstol = 1e-3, save_start = false)\n",
    "n_ode = AugmentedNDELayer(n_ode, 20)\n",
    "ps = n_ode.p\n",
    "model = Chain((x, p = n_ode.p) -> n_ode(x, p), # En primer lugar manda el input a la red neuronal y luego los parámetros\n",
    "                Array,  # Lo que devuelve la NODE es la solución desde t0 a t1 y devuelve f en cada paso de tiempo\n",
    "                diffeqarray_to_array, # Esto solo deja la matriz 21x201\n",
    "                Dense(21, 1)) # Esta f pasa por una capa densa para que la salida sea un número"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos la función costo para esta red neruronal, igual que antes usamos mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Flux.dataloader(t_train, y_train, batchsize = 20, shuffle = true)\n",
    "loss_node(x, y) = mean((model(x) .- y) .^ 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuraccy_train = []\n",
    "accuraccy_test = []\n",
    "loss_train = []\n",
    "loss_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "function accuracy(y)\n",
    "    num_correct = 0\n",
    "    predictions = model(t_train)\n",
    "    for i in 1:length(predictions)\n",
    "        if abs(predictions[1,i] - y[1,i]) < 0.1\n",
    "            num_correct += 1\n",
    "        end\n",
    "    end\n",
    "    return (num_correct/length(predictions)) * 100.0\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seteamos la cantidad de épocas a entrenar, el ratio de aprendizaje y el modelo de optimización que vamos a utilizar. Además creamos la función callback para obtener información de cada época de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = ADAM(0.005)\n",
    "iter = 0\n",
    "cb = function()\n",
    "    global iter\n",
    "    iter += 1\n",
    "    if iter % length(data) == 0\n",
    "        actual_loss = loss_node(data.data[1], data.data[2])\n",
    "        println(\"Iteration $iter || Loss = $actual_loss\")\n",
    "        push!(loss_train, actual_loss)\n",
    "        push!(loss_test, loss_node(data.data[1], y_test))\n",
    "        push!(accuracy_train, accuracy(y_train))\n",
    "        push!(accuracy_test, accuracy(y_test))\n",
    "    end\n",
    "end\n",
    "\n",
    "for _ in 1:150\n",
    "    Flux.train!(loss_node, Flux.params(ps, model), data, opt, cb = cb)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(t_train[1,:],y_train[1,:], label=\"Train data\", title=\"Predicción de la función seno con ruido\")\n",
    "scatter!(t_train[1,:],y_test[1,:], label=\"Test data\")\n",
    "scatter!(t_train[1,:],model(t_train)[1,:],label = \"predicción\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora veamos el Loss en función de las épocas de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(loss_train, label=\"train loss\",xlabel = \"Epochs\", ylabel = \"Loss\", title = \"Loss on train vs Epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(loss_test, label=\"test loss\",xlabel = \"Epochs\", ylabel = \"Loss\", title = \"Loss on test vs Epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"Maximum accuracy on train: \", maximum(accuracy_train), \"%\")\n",
    "plot(accuracy_train, label=\"train accuracy\",xlabel = \"Epochs\", ylabel = \"Accuracy\", title = \"Accuracy on train vs Epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"Maximum accuracy on test: \", maximum(accuracy_test), \"%\")\n",
    "plot(accuracy_test, label = \"test accuracy\",xlabel = \"Epochs\", ylabel = \"Accuracy\", title = \"Accuracy on test vs Epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.1",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
